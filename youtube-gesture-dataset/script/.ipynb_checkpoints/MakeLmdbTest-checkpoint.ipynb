{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f55c5a9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Duplicate registrations for type 'experimentalOptimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mEstimate3d\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "File \u001b[1;32m~\\ProjectHcb\\youtube-gesture-dataset\\script\\Estimate3d.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential, model_from_json\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m K\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hcb\\lib\\site-packages\\tensorflow\\__init__.py:473\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(_current_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    472\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 473\u001b[0m     \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hcb\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:41\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_module_globals[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_name] \u001b[38;5;241m=\u001b[39m module\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hcb\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hcb\\lib\\site-packages\\keras\\__init__.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hcb\\lib\\site-packages\\keras\\models\\__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hcb\\lib\\site-packages\\keras\\engine\\functional.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer_utils\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional_utils\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hcb\\lib\\site-packages\\keras\\engine\\base_layer.py:43\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m node \u001b[38;5;28;01mas\u001b[39;00m node_module\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixed_precision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autocast_variable\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixed_precision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loss_scale_optimizer\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixed_precision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m policy\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layer_serialization\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hcb\\lib\\site-packages\\keras\\mixed_precision\\loss_scale_optimizer.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizers\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixed_precision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loss_scale \u001b[38;5;28;01mas\u001b[39;00m keras_loss_scale_module\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer_experimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizer \u001b[38;5;28;01mas\u001b[39;00m optimizer_experimental\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizer_v2\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils \u001b[38;5;28;01mas\u001b[39;00m optimizer_utils\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hcb\\lib\\site-packages\\keras\\optimizer_experimental\\optimizer.py:649\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    642\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    643\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRestoring functional Optimizers from SavedModels is not currently \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    644\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported. Please file a feature request if this limitation bothers \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    645\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    648\u001b[0m \u001b[38;5;66;03m# Register the optimizer for loading from saved_model purpose.\u001b[39;00m\n\u001b[1;32m--> 649\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_revived_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexperimentalOptimizer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOptimizer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mversions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVersionedTypeRegistration\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobject_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mRestoredOptimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m            \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_producer_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_consumer_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hcb\\lib\\site-packages\\tensorflow\\python\\saved_model\\revived_types.py:133\u001b[0m, in \u001b[0;36mregister_revived_type\u001b[1;34m(identifier, predicate, versions)\u001b[0m\n\u001b[0;32m    130\u001b[0m   version_numbers\u001b[38;5;241m.\u001b[39madd(registration\u001b[38;5;241m.\u001b[39mversion)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m identifier \u001b[38;5;129;01min\u001b[39;00m _REVIVED_TYPE_REGISTRY:\n\u001b[1;32m--> 133\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDuplicate registrations for type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    135\u001b[0m _REVIVED_TYPE_REGISTRY[identifier] \u001b[38;5;241m=\u001b[39m (predicate, versions)\n\u001b[0;32m    136\u001b[0m _TYPE_IDENTIFIERS\u001b[38;5;241m.\u001b[39mappend(identifier)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Duplicate registrations for type 'experimentalOptimizer'"
     ]
    }
   ],
   "source": [
    "import Estimate3d\n",
    "import pickle\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c4be3a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Estimate3d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3D_model/multistage_best/model_multistage_dropout.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m model_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3D_model/multistage_best/model_multistage_weight_dropout.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m estimate3d \u001b[38;5;241m=\u001b[39m \u001b[43mEstimate3d\u001b[49m\u001b[38;5;241m.\u001b[39mInference(model_json, model_weight)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Estimate3d' is not defined"
     ]
    }
   ],
   "source": [
    "model_json = '3D_model/multistage_best/model_multistage_dropout.json'\n",
    "model_weight = '3D_model/multistage_best/model_multistage_weight_dropout.h5'\n",
    "estimate3d = Estimate3d.Inference(model_json, model_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f207700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "\n",
    "import lmdb\n",
    "import pyarrow\n",
    "import numpy as np\n",
    "from tqdm import tqdm_gui\n",
    "import unicodedata\n",
    "import joblib\n",
    "from config import my_config\n",
    "from data_utils import *\n",
    "\n",
    "\n",
    "def read_subtitle(vid):\n",
    "    postfix_in_filename = '-en.vtt'\n",
    "    file_list = glob.glob(my_config.SUBTITLE_PATH + '/*' + vid + postfix_in_filename)\n",
    "    if len(file_list) > 1:\n",
    "        print('more than one subtitle. check this.', file_list)\n",
    "        assert False\n",
    "    if len(file_list) == 1:\n",
    "        return WebVTT().read(file_list[0])\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "# turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "\n",
    "# lowercase, trim, and remove non-letter characters\n",
    "def normalize_string(s, lang='en'):\n",
    "    # s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([,.!?])\", r\" \\1 \", s)  # isolate some marks\n",
    "    s = re.sub(r\"(['])\", r\"\", s)  # remove apostrophe (i.e., shouldn't --> shouldnt)\n",
    "    s = re.sub(r\"[^가-힣0-9,.!?]+\", r\" \", s)  # replace other characters with whitespace\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def normalize_subtitle(vtt_subtitle):\n",
    "    for i, sub in enumerate(vtt_subtitle):\n",
    "        vtt_subtitle[i].text = normalize_string(vtt_subtitle[i].text)\n",
    "    return vtt_subtitle\n",
    "\n",
    "def normalize_skeleton(data, resize_factor=None):\n",
    "    def distance(x1, y1, x2, y2):\n",
    "        return np.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n",
    "\n",
    "    if data[1 * 2] == 0 or data[2 * 2] == 0 or data[5 * 2] == 0:  # neck or shoulder joints are missing\n",
    "        return [np.nan] * len(data), resize_factor\n",
    "\n",
    "    anchor_pt = (data[1 * 2], data[1 * 2 + 1])  # neck\n",
    "    if resize_factor is None:\n",
    "        neck_height = float(abs(data[1] - data[1 * 2 + 1]))\n",
    "        shoulder_length = distance(data[1 * 2], data[1 * 2 + 1], data[2 * 2], data[2 * 2 + 1]) + \\\n",
    "                          distance(data[1 * 2], data[1 * 2 + 1], data[5 * 2], data[5 * 2 + 1])\n",
    "        resized_neck_height = neck_height / float(shoulder_length)\n",
    "        if resized_neck_height > 0.6:\n",
    "            resize_factor = shoulder_length * resized_neck_height / 0.6\n",
    "        else:\n",
    "            resize_factor = shoulder_length\n",
    "\n",
    "    normalized_data = data.copy()\n",
    "    for i in range(0, len(data), 2):\n",
    "        if data[i] > 0:\n",
    "            normalized_data[i] = (data[i] - anchor_pt[0]) / resize_factor\n",
    "        else:\n",
    "            normalized_data[i] = np.nan\n",
    "        if data[i + 1] > 0:\n",
    "            normalized_data[i + 1] = (data[i + 1] - anchor_pt[1]) / resize_factor\n",
    "        else:\n",
    "            normalized_data[i + 1] = np.nan\n",
    "\n",
    "    return normalized_data, resize_factor\n",
    "\n",
    "def normalize_skeleton_3d(data, resize_factor=None):\n",
    "    def distance(x1, y1, z1, x2, y2, z2):\n",
    "        return np.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2 +(z1 - z2) ** 2)\n",
    "\n",
    "    if data[1 * 3] == 0 or data[2 * 3] == 0 or data[5 * 3] == 0:  # neck or shoulder joints are missing\n",
    "        return [np.nan] * len(data), resize_factor\n",
    "\n",
    "    anchor_pt = (data[1 * 3], data[1 * 3 + 1], data[1 * 3 + 2])  # neck\n",
    "    if resize_factor is None:\n",
    "        neck_height = float(abs(data[1] - data[1 * 3 + 1]))\n",
    "        shoulder_length = distance(data[1 * 3], data[1 * 3 + 1], data[1 * 3 + 2], data[2 * 3], data[2 * 3 + 1], data[2 * 3 + 2]) + \\\n",
    "                          distance(data[1 * 3], data[1 * 3 + 1], data[1 * 3 + 2], data[5 * 3], data[5 * 3 + 1], data[5 * 3 + 2])\n",
    "        resized_neck_height = neck_height / float(shoulder_length)\n",
    "        if resized_neck_height > 0.6:\n",
    "            resize_factor = shoulder_length * resized_neck_height / 0.6\n",
    "        else:\n",
    "            resize_factor = shoulder_length\n",
    "\n",
    "    normalized_data = data.copy()\n",
    "    for i in range(0, len(data), 3):\n",
    "        if data[i] > 0:\n",
    "            normalized_data[i] = (data[i] - anchor_pt[0]) / resize_factor\n",
    "        else:\n",
    "            normalized_data[i] = np.nan\n",
    "        if data[i + 1] > 0:\n",
    "            normalized_data[i + 1] = (data[i + 1] - anchor_pt[1]) / resize_factor\n",
    "        else:\n",
    "            normalized_data[i + 1] = np.nan\n",
    "        if data[i + 2] > 0:\n",
    "            normalized_data[i + 2] = (data[i + 2] - anchor_pt[2]) / resize_factor\n",
    "        else:\n",
    "            normalized_data[i + 2] = np.nan\n",
    "\n",
    "    return normalized_data\n",
    "\n",
    "\n",
    "def make_lmdb_gesture_dataset():\n",
    "    if not os.path.exists(my_config.OUTPUT_PATH):\n",
    "        os.makedirs(my_config.OUTPUT_PATH)\n",
    "\n",
    "    map_size = 1024 * 20  # in MB\n",
    "    map_size <<= 20  # in B\n",
    "    db = [lmdb.open(os.path.join(my_config.OUTPUT_PATH, 'lmdb_train'), map_size=map_size),\n",
    "            lmdb.open(os.path.join(my_config.OUTPUT_PATH, 'lmdb_val'), map_size=map_size),\n",
    "            lmdb.open(os.path.join(my_config.OUTPUT_PATH, 'lmdb_test'), map_size=map_size)]\n",
    "    n_saved_clips = [0, 0, 0]\n",
    "\n",
    "    # delete previous items\n",
    "    for i in range(3):\n",
    "        with db[i].begin(write=True) as txn:\n",
    "            txn.drop(db[i].open_db())\n",
    "            print(txn.stat())\n",
    "\n",
    "    video_files = sorted(glob.glob(my_config.VIDEO_PATH + \"/*.mp4\"), key=os.path.getmtime)\n",
    "    for v_i, video_file in enumerate(tqdm_gui(video_files)):\n",
    "        vid = os.path.split(video_file)[1][-15:-4]\n",
    "        print(vid)\n",
    "\n",
    "        # load clip, video, and subtitle\n",
    "        clip_data = load_clip_data(vid)\n",
    "        if clip_data is None:\n",
    "            print('[WARNING] clip data file does not exist! skip this video.')\n",
    "            clip_data = []\n",
    "\n",
    "        video_wrapper = read_video(my_config.VIDEO_PATH, vid)\n",
    "\n",
    "        subtitle_type = my_config.SUBTITLE_TYPE\n",
    "        subtitle = SubtitleWrapper(vid, subtitle_type).get()\n",
    "        if subtitle is None:\n",
    "            print('[WARNING] subtitle does not exist! skip this video.')\n",
    "            clip_data = []\n",
    "\n",
    "\n",
    "        # load audio\n",
    "        '''\n",
    "        audio_path = os.path.join(my_config.VIDEO_PATH, '{}.mp3'.format(vid))\n",
    "        audio = AudioWrapper(audio_path)\n",
    "        '''\n",
    "\n",
    "\n",
    "        # load 3D poses\n",
    "        '''\n",
    "        if my_config.USE_3D_POSE:\n",
    "            pose_path = my_config.POSE_3D_DATA_PATH\n",
    "            with open(pose_path, 'rb') as f:\n",
    "                poses_3d = pickle.load(f)\n",
    "        '''\n",
    "\n",
    "        # process\n",
    "        clips = [{'vid': vid, 'framerate': video_wrapper.framerate, 'clips': []},  # train\n",
    "                 {'vid': vid, 'framerate': video_wrapper.framerate, 'clips': []},  # val\n",
    "                 {'vid': vid, 'framerate': video_wrapper.framerate, 'clips': []}]  # test\n",
    "\n",
    "        word_index = 0\n",
    "        valid_clip_count = 0\n",
    "\n",
    "        for clip_idx, clip in enumerate(clip_data):\n",
    "            start_frame_no, end_frame_no, clip_pose_all = clip['clip_info'][0], clip['clip_info'][1], clip['frames']\n",
    "            clip_word_list = []\n",
    "\n",
    "            # skip FALSE clips\n",
    "            if not clip['clip_info'][2]:\n",
    "                continue\n",
    "\n",
    "            # train/val/test split\n",
    "            if v_i % 10 == 0:\n",
    "                dataset_idx = 2  # test\n",
    "            elif v_i % 10 == 1:\n",
    "                dataset_idx = 1  # val\n",
    "            else:\n",
    "                dataset_idx = 0  # train\n",
    "            valid_clip_count += 1\n",
    "\n",
    "            '''\n",
    "            # extract audio feature\n",
    "            audio_feat, audio_raw = audio.extract_audio_feat(video_wrapper.total_frames, start_frame_no, end_frame_no)\n",
    "            '''\n",
    "\n",
    "            # get subtitle that fits clip\n",
    "            for ib in range(word_index - 1, len(subtitle)):\n",
    "                if ib < 0:\n",
    "                    continue\n",
    "\n",
    "                word_s = subtitle[ib]['start']\n",
    "                word_e = subtitle[ib]['end']\n",
    "                word = subtitle[ib]['word']\n",
    "                if video_wrapper.second2frame(word_s) >= end_frame_no:\n",
    "                    word_index = ib\n",
    "                    break\n",
    "\n",
    "                if video_wrapper.second2frame(word_e) <= start_frame_no:\n",
    "                    continue\n",
    "\n",
    "                word = normalize_string(word, my_config.LANG)\n",
    "                if len(word) > 0:\n",
    "                    clip_word_list.append([word, word_s, word_e])\n",
    "\n",
    "            if clip_word_list:\n",
    "                clip_skeleton = []\n",
    "                custom_clip_skeleton = []\n",
    "                clip_skeleton_3d = []\n",
    "\n",
    "                n_detected_poses = 0\n",
    "\n",
    "                # get skeletons of the upper body in the clip\n",
    "                n_joints = 8\n",
    "                custom_joints = 15\n",
    "                for frame in clip_pose_all:\n",
    "                    if frame:\n",
    "                        skeleton = get_skeleton_from_frame(frame)[:n_joints * 3]\n",
    "                        custom_skeleton = get_skeleton_from_frame(frame)[:custom_joints * 3]\n",
    "                        del skeleton[2::3]  # remove confidence values\n",
    "                        del custom_skeleton[2::3]  # remove confidence values\n",
    "                        skeleton, _ = normalize_skeleton(skeleton)\n",
    "                        custom_skeleton, _ = normalize_skeleton(custom_skeleton)\n",
    "                        clip_skeleton.append(skeleton)\n",
    "                        custom_clip_skeleton.append(custom_skeleton)\n",
    "                        n_detected_poses += 1\n",
    "                    else:  # frame with no skeleton\n",
    "                        clip_skeleton.append([np.nan] * (n_joints * 2))\n",
    "                        custom_clip_skeleton.append([np.nan] * (custom_joints * 2))\n",
    "                '''\n",
    "                if my_config.USE_3D_POSE:\n",
    "                    key_str = '{}_clip{:03d}'.format(vid, clip_idx)\n",
    "                    if key_str not in poses_3d:\n",
    "                        print('{} is not in the 3d pose data'.format(key_str))\n",
    "                        continue\n",
    "                    clip_skeleton_3d = poses_3d[key_str]\n",
    "                '''\n",
    "\n",
    "\n",
    "                # proceed if skeleton list is not empty\n",
    "                if n_detected_poses > 5:\n",
    "                    # save subtitles and skeletons corresponding to clips\n",
    "                    n_saved_clips[dataset_idx] += 1\n",
    "                    clip_skeleton = np.asarray(clip_skeleton, dtype=np.float16)\n",
    "                    clip_skeleton_3d_list = infer3d.make3D(custom_clip_skeleton)\n",
    "                    clip_skeleton_3d_result = []\n",
    "                    for i in range(len(clip_skeleton_3d_list)):\n",
    "                        normalize_skeleton_3d = normalize_skeleton_3d(clip_skeleton_3d_list[i])\n",
    "                        neck_x = (normalize_skeleton_3d[0][0] + normalize_skeleton_3d[1][0]) / 2;\n",
    "                        neck_y = (normalize_skeleton_3d[0][1] + normalize_skeleton_3d[1][1]) / 2;\n",
    "                        neck_z = (normalize_skeleton_3d[0][2] + normalize_skeleton_3d[1][2]) / 2;\n",
    "                        normalize_skeleton_3d.insert(1, [neck_x, neck_y, neck_z])\n",
    "                        clip_skeleton_3d_result.append(normalize_skeleton_3d)\n",
    "                    clip_skeleton_3d = np.asarray(clip_skeleton_3d_result)\n",
    "                    clips[dataset_idx]['clips'].append({'words': clip_word_list,\n",
    "                                                        'skeletons': clip_skeleton,\n",
    "                                                        'skeletons_3d': clip_skeleton_3d.astype('float16'),\n",
    "\n",
    "                                                        #'audio_feat': audio_feat, 'audio_raw': audio_raw,\n",
    "\n",
    "                                                        'start_frame_no': start_frame_no, 'end_frame_no': end_frame_no,\n",
    "                                                        'start_time': video_wrapper.frame2second(start_frame_no),\n",
    "                                                        'end_time': video_wrapper.frame2second(end_frame_no)\n",
    "                                                        })\n",
    "\n",
    "                    print('{} ({}, {})'.format(vid, start_frame_no, end_frame_no))\n",
    "                else:\n",
    "                    print('{} ({}, {}) - consecutive missing frames'.format(vid, start_frame_no, end_frame_no))\n",
    "\n",
    "        # write to db\n",
    "        for i in range(3):\n",
    "            with db[i].begin(write=True) as txn:\n",
    "                if len(clips[i]['clips']) > 0:\n",
    "                    k = '{:010}'.format(v_i).encode('ascii')\n",
    "                    v = pyarrow.serialize(clips[i]).to_buffer()\n",
    "                    txn.put(k, v)\n",
    "\n",
    "    print('no. of saved clips: train {}, val {}, test {}'.format(n_saved_clips[0], n_saved_clips[1], n_saved_clips[2]))\n",
    "\n",
    "    # close db\n",
    "    for i in range(3):\n",
    "        db[i].sync()\n",
    "        db[i].close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cc0787",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_lmdb_gesture_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
